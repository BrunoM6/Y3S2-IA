{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d04c6591",
   "metadata": {},
   "source": [
    "# Streaming Videos Cache Optimization Problem\n",
    "Using cache servers, we can optimize requests for videos from a data center to endpoints. Based on the predicted requests from endpoints, can we find a way to optimize the distribution and storage of said videos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4340f43",
   "metadata": {},
   "source": [
    "## Input and Parsing\n",
    "Data is provided as text. We can parse said data into various tokens. We read from `data/input.txt` in this case.\n",
    "The `problem_description` array holds, in order, from 0 to 4, the number of videos, number of endpoints, number of request descriptions, number of cache servers, and the capacity of each cache server in megabytes.\n",
    "The `video_size` array holds the size of each video in MB.\n",
    "We then parse based on the ammount of endpoints, to connect each endpoint to the caches. The `endpoint_data_description` describes the latency between an endpoint (serves as the index of the array) and the data center (latency is the value stored), and the `endpoint_cache_description` has the key/value specification of key:(endpoint, cache) -> value:latency.\n",
    "Finally, `request_description` is a dictionary that holds the ammount of requests a certain video at an endpoint holds, specification of key:(endpoint, video) -> value:nº of requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41de98bf-39dd-47ee-ad0a-84030113bc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197978\n"
     ]
    }
   ],
   "source": [
    "def parse_results(file: str):\n",
    "    problem_description = []\n",
    "    video_size = []\n",
    "    endpoint_data_description = []\n",
    "    endpoint_cache_description = {}\n",
    "    request_description = {}\n",
    "    with open('data/' + file, 'r') as file:\n",
    "        line = file.readline()\n",
    "        tokens = line.strip().split()\n",
    "        for token in tokens:\n",
    "            problem_description.append(int(token))\n",
    "        line = file.readline()\n",
    "        tokens = line.strip().split()\n",
    "        for token in tokens:\n",
    "            video_size.append(int(token))\n",
    "        i = 0\n",
    "        while i != problem_description[1]:\n",
    "            line = file.readline()\n",
    "            tokens = line.strip().split()\n",
    "            endpoint_data_description.append(int(tokens[0]))\n",
    "            connections = int(tokens[1])\n",
    "            j = 0\n",
    "            while j < connections:\n",
    "                line = file.readline()\n",
    "                tokens = line.strip().split()\n",
    "                endpoint_cache_description[(i, tokens[0])] = tokens[1]\n",
    "                j += 1\n",
    "            i += 1\n",
    "        i = 0\n",
    "        c = 0\n",
    "        while i != problem_description[2]:\n",
    "            i+=1\n",
    "            line = file.readline()\n",
    "            tokens = line.strip().split()\n",
    "            key = (tokens[1], tokens[0])\n",
    "            if key in request_description:\n",
    "                request_description[key] += tokens[2]\n",
    "            else:\n",
    "                request_description[key] = token[2]\n",
    "    return problem_description, video_size, endpoint_data_description, endpoint_cache_description, request_description\n",
    "\n",
    "problem_description, video_size, endpoint_data_description, endpoint_cache_description, request_description = parse_results('kittens.in.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a51df3c",
   "metadata": {},
   "source": [
    "## Problem State\n",
    "The problem state is defined by a dictionary that maps a cache to a list of videos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93dbfa4",
   "metadata": {},
   "source": [
    "## Goal and Scoring\n",
    "Our goal is to maximize time saved by the caches, for this, we must go through our current cache configuration and figure out how much time we are saving in total based on the requests. Then, we multiply this value, in milliseconds, by 1000, to get the score. \n",
    "Time Saved (Request Description) = Nº of Requests * min(Latency of Data Center - Latency of Cache with Video)\n",
    "Also, when re-scoring our problem, it makes more sense to update the current score with the alteration instead of re-calculating the score from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3234972a",
   "metadata": {},
   "outputs": [
    {
     "ename": "_IncompleteInputError",
     "evalue": "incomplete input (4028207760.py, line 3)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\n    ^\n\u001b[31m_IncompleteInputError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "def score(problem_description: list, ):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
