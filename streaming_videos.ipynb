{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d04c6591",
   "metadata": {},
   "source": [
    "# Streaming Videos Cache Optimization Problem\n",
    "Using cache servers, we can optimize requests for videos from a data center to endpoints. Based on the predicted requests from endpoints, can we find a way to optimize the distribution and storage of said videos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4340f43",
   "metadata": {},
   "source": [
    "## Input and Parsing\n",
    "Data is provided as text. We can parse said data into various tokens. We read from `data/input.txt` in this case.\n",
    "The `problem_description` array holds, in order, from 0 to 4, the number of videos, number of endpoints, number of request descriptions, number of cache servers, and the capacity of each cache server in megabytes.\n",
    "The `video_size` array holds the size of each video in MB.\n",
    "We then parse based on the ammount of endpoints, to connect each endpoint to the caches. The `endpoint_data_description` describes the latency between an endpoint (serves as the index of the array) and the data center (latency is the value stored), and the `endpoint_cache_description` has the key/value specification of key:(endpoint, cache) -> value:latency.\n",
    "Finally, `request_description` is a dictionary that holds the ammount of requests a certain video at an endpoint holds, specification of key:(endpoint, video) -> value:nº of requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41de98bf-39dd-47ee-ad0a-84030113bc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197978\n"
     ]
    }
   ],
   "source": [
    "def parse_results(file: str):\n",
    "    problem_description = []\n",
    "    video_size = []\n",
    "    endpoint_data_description = []\n",
    "    endpoint_cache_description = {}\n",
    "    request_description = {}\n",
    "    with open('data/' + file, 'r') as file:\n",
    "        line = file.readline()\n",
    "        tokens = line.strip().split()\n",
    "        for token in tokens:\n",
    "            problem_description.append(int(token))\n",
    "        line = file.readline()\n",
    "        tokens = line.strip().split()\n",
    "        for token in tokens:\n",
    "            video_size.append(int(token))\n",
    "        i = 0\n",
    "        while i != problem_description[1]:\n",
    "            line = file.readline()\n",
    "            tokens = line.strip().split()\n",
    "            endpoint_data_description.append(int(tokens[0]))\n",
    "            connections = int(tokens[1])\n",
    "            j = 0\n",
    "            while j < connections:\n",
    "                line = file.readline()\n",
    "                tokens = line.strip().split()\n",
    "                endpoint_cache_description[(i, tokens[0])] = tokens[1]\n",
    "                j += 1\n",
    "            i += 1\n",
    "        i = 0\n",
    "        c = 0\n",
    "        while i != problem_description[2]:\n",
    "            i+=1\n",
    "            line = file.readline()\n",
    "            tokens = line.strip().split()\n",
    "            key = (tokens[1], tokens[0])\n",
    "            if key in request_description:\n",
    "                request_description[key] += tokens[2]\n",
    "            else:\n",
    "                request_description[key] = token[2]\n",
    "    return problem_description, video_size, endpoint_data_description, endpoint_cache_description, request_description\n",
    "\n",
    "problem_description, video_size, endpoint_data_description, endpoint_cache_description, request_description = parse_results('kittens.in.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a51df3c",
   "metadata": {},
   "source": [
    "## Problem State\n",
    "The problem state is defined by a dictionary that maps a cache to a list of videos. We must careful with the underlying constraints of the total video sizes not surpassing cache size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93dbfa4",
   "metadata": {},
   "source": [
    "## Goal and Scoring\n",
    "Our goal is to maximize time saved by the caches, for this, we must go through our current cache configuration and figure out how much time we are saving in total based on the requests. Then, we multiply this value, in milliseconds, by 1000, to get the score. \n",
    "Time Saved (Request Description) = Nº of Requests * min(Latency of Data Center - Latency of Cache with Video)\n",
    "Also, when re-scoring our problem, it makes more sense to update the current score with the alteration instead of re-calculating the score from scratch.\n",
    "The score presumes a valid problem state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3234972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def score(problem_state: dict, endpoint_data_description: list, endpoint_cache_description: dict, request_description: dict) -> float:\n",
    "    score = 0\n",
    "    for (endpoint, video), request_number in request_description:\n",
    "        data_center_latency = endpoint_data_description[endpoint]\n",
    "        cache_latency = data_center_latency\n",
    "        for cache, videos in problem_state:\n",
    "            if video in videos:\n",
    "                cache_latency = min(cache_latency, endpoint_cache_description[(endpoint, cache)])\n",
    "        score += (data_center_latency - cache_latency) * request_number\n",
    "    return math.floor(score * 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f6a01b",
   "metadata": {},
   "source": [
    "### Updating the score\n",
    "Now, for computational efficiency effects, we create a re-score function that based on a cache change, a current score and the descriptions, updates the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdafcc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_score(problem_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
